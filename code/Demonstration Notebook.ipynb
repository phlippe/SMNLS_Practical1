{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMNLS Practical 1\n",
    "This notebook serves as demonstration of loading a trained model and performing inference.\n",
    "\n",
    "First step is loading all necessary packages/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os \n",
    "import sys\n",
    "from model import NLIModel\n",
    "from data import load_SNLI_datasets, debug_level, NLIData, SNLIDataset\n",
    "from mutils import load_model, load_model_from_args, load_args, args_to_params\n",
    "from infer import run_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading parameter configuration from \"results/BiLSTM_Max_SGD_DP/param_config.pik\"\n",
      "Loaded vocabulary of size 61498\n",
      "==================================================\n",
      "Dataset statistics train\n",
      "--------------------------------------------------\n",
      "Number of examples: 549367\n",
      "Labelwise amount:\n",
      "\t- -: 0\n",
      "\t- neutral: 182764\n",
      "\t- entailment: 183416\n",
      "\t- contradiction: 183187\n",
      "Number of invalid examples: 0\n",
      "==================================================\n",
      "Amount of missing words: 0.09%\n",
      "==================================================\n",
      "Dataset statistics dev\n",
      "--------------------------------------------------\n",
      "Number of examples: 9842\n",
      "Labelwise amount:\n",
      "\t- -: 0\n",
      "\t- neutral: 3235\n",
      "\t- entailment: 3329\n",
      "\t- contradiction: 3278\n",
      "Number of invalid examples: 0\n",
      "==================================================\n",
      "Amount of missing words: 0.10%\n",
      "==================================================\n",
      "Dataset statistics test\n",
      "--------------------------------------------------\n",
      "Number of examples: 9824\n",
      "Labelwise amount:\n",
      "\t- -: 0\n",
      "\t- neutral: 3219\n",
      "\t- entailment: 3368\n",
      "\t- contradiction: 3237\n",
      "Number of invalid examples: 0\n",
      "==================================================\n",
      "Amount of missing words: 0.09%\n",
      "Loading checkpoint \"results/BiLSTM_Max_SGD_DP/checkpoint_020.tar\"\n",
      "Loading checkpoint \"results/BiLSTM_Max_SGD_DP/checkpoint_009.tar\"\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_MODEL = \"results/BiLSTM_Max_SGD_DP\"\n",
    "\n",
    "model_params = load_args(PATH_TO_MODEL)\n",
    "model = load_model_from_args(model_params, PATH_TO_MODEL, load_best_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise: four children are playing in some water .\n",
      "Hypothesis: the children are muddy .\n",
      "Premise: four children are playing in some water .\n",
      "Hypothesis: the children are wet .\n",
      "Premise: a group of people stand near and on a large black square on the ground with some yellow writing on it .\n",
      "Hypothesis: a group of people wait\n",
      "Amount of missing words: 0.00%\n",
      "Inference process: 0.00%\r",
      "tensor([[0.9744, 0.0250, 0.0006],\n",
      "        [0.0767, 0.9233, 0.0001],\n",
      "        [0.5330, 0.4661, 0.0009]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "====================================================================================================\n",
      " Example 1\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Premise: four children are playing in some water .\n",
      " Hypothesis: the children are muddy .\n",
      " Prediction: neutral\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      " Example 2\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Premise: four children are playing in some water .\n",
      " Hypothesis: the children are wet .\n",
      " Prediction: entailment\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      " Example 3\n",
      "----------------------------------------------------------------------------------------------------\n",
      " Premise: a group of people stand near and on a large black square on the ground with some yellow writing on it .\n",
      " Hypothesis: a group of people wait\n",
      " Prediction: neutral\n",
      "====================================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PREMISE = [\"Four children are playing in some water . \", \n",
    "           \"Four children are playing in some water . \",\n",
    "           \"A group of people stand near and on a large black square on the ground with some yellow writing on it . \"]\n",
    "HYPOTHESIS = [\"The children are muddy .\", \n",
    "              \"The children are wet .\", \n",
    "              \"a group of people wait \"]\n",
    "\n",
    "input_file = \"\\n\".join([p + \" #SEP# \" + h for p,h in zip(PREMISE, HYPOTHESIS)])\n",
    "run_inference(model, input_file, output_file=None, load_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
