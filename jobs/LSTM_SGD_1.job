#!/bin/bash

#SBATCH --job-name=NLI_LSTM_SGD_1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=2
#SBATCH --ntasks-per-node=1
#SBATCH --time=24:00:00
#SBATCH --mem=60000M
#SBATCH --partition=gpu_shared_course
#SBATCH --gres=gpu:1

module purge
module load eb

module load Python/3.6.3-foss-2017b
module load cuDNN/7.0.5-CUDA-9.0.176
module load NCCL/2.0.5-CUDA-9.0.176
export LD_LIBRARY_PATH=/hpc/eb/Debian9/cuDNN/7.1-CUDA-8.0.44-GCCcore-5.4.0/lib64:$LD_LIBRARY_PATH

EXPDIR=$TMPDIR
mkdir -p $EXPDIR
mkdir -p $EXPDIR/code
rsync -a $HOME/SMNLS_Practical1/code/*.py $EXPDIR/code/
rsync -a $HOME/SMNLS_Practical1/code/small_glove_* $EXPDIR/code/
rsync -a $HOME/SMNLS_Practical1/snli_1.0 $EXPDIR/
cd $EXPDIR/code

srun python3 -u train.py --cluster --model 1 --epochs 100 --optimizer 0 --learning_rate 0.1 --weight_decay 1e-5 --lr_max_red_steps 5 --embed_dim 2048 --seed 42 --tensorboard --restart --intermediate_evals --checkpoint_path checkpoints/LSTM_SGD

rsync -av checkpoints/* $HOME/SMNLS_Practical1/code/checkpoints/

cd ../..
# rm -rf $EXPDIR
 
cd $HOME
